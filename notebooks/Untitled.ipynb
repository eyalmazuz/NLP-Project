{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e06793f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from datasets import Dataset\n",
    "import evaluate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import f1_score, roc_auc_score, accuracy_score\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, AutoModelForSequenceClassification\n",
    "from transformers import TrainingArguments, Trainer, IntervalStrategy\n",
    "from transformers import Seq2SeqTrainingArguments, Seq2SeqTrainer, DataCollatorForSeq2Seq\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from sklearn.model_selection import LeavePGroupsOut\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94ad816e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/annotated_trees_101.csv', index_col=0)\n",
    "df.columns = ['node_id', 'tree_id', 'timestamp', 'author', 'text', 'parent',\n",
    "       'Aggressive', 'Agree But', 'Agree To Disagree', 'Alternative', 'Answer',\n",
    "       'Attack Validity', 'BAD', 'Clarification', 'Complaint', 'Convergence',\n",
    "       'Counter Argument', 'Critical Question', 'Direct No', 'Double Voicing',\n",
    "       'Extension', 'Irrelevance', 'Moderation', 'Neg Transformation',\n",
    "       'Nitpicking', 'No Reason Disagreement', 'Personal', 'Positive',\n",
    "       'Repetition', 'Rephrase Attack', 'Request Clarification', 'Ridicule',\n",
    "       'Sarcasm', 'Softening', 'Sources', 'Viable Transformation',\n",
    "       'W Qualifiers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be62f83d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_post_comment_pairs(df: pd.DataFrame, model) -> pd.DataFrame:\n",
    "    tuples = []\n",
    "    for row in tqdm(df.itertuples(), total=len(df)):\n",
    "        if row.parent == -1:\n",
    "            continue\n",
    "\n",
    "        tree_id = row.tree_id\n",
    "        comment = row.text\n",
    "        root = df[(df['tree_id'] == tree_id) & (df['parent'] == -1)]['text'].values[0]\n",
    "\n",
    "        if model.startswith('t5'):\n",
    "            tuples.append((root, comment, tree_id, row.timestamp, row.labels))\n",
    "\n",
    "        else:\n",
    "            # row starts from 7 because itertuples also returns the index in the tuple.\n",
    "            tuples.append((root, comment, tree_id, row.timestamp, *row[7:]))\n",
    "\n",
    "    if model.startswith('t5'):\n",
    "        tuples_df = pd.DataFrame(tuples, columns=['post', 'comment', 'tree_id', 'time', 'labels'])\n",
    "\n",
    "    else:\n",
    "        tuples_df = pd.DataFrame(tuples, columns=['post', 'comment', 'tree_id', 'time'] + df.columns[6:].tolist())\n",
    "    tuples_df['inputs'] = 'comment: ' + tuples_df.comment.str.cat(' post: ' + tuples_df.post)\n",
    "\n",
    "    # This makes sure that the labels are the last columns in the dataframe\n",
    "    new_columns_order = tuples_df.columns[:4].tolist() + [tuples_df.columns[-1]] + tuples_df.columns[4:-1].tolist()\n",
    "    tuples_df = tuples_df[new_columns_order]\n",
    "\n",
    "    return tuples_df\n",
    "\n",
    "\n",
    "def remove_bad_comments(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    removed_tokens = ['[removed]', '[deleted]']\n",
    "\n",
    "    df = df[~(df.post.isin(removed_tokens)) & ~(df.comment.isin(removed_tokens))]\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04468182",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d15a0f8a9af4422e9576e34b13c43e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10559 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pairs_df = create_post_comment_pairs(df, 'bert')\n",
    "pairs_df = remove_bad_comments(pairs_df)\n",
    "pairs_df = pairs_df.drop(['post', 'comment'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75d6e1d5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tree_id</th>\n",
       "      <th>time</th>\n",
       "      <th>inputs</th>\n",
       "      <th>Aggressive</th>\n",
       "      <th>Agree But</th>\n",
       "      <th>Agree To Disagree</th>\n",
       "      <th>Alternative</th>\n",
       "      <th>Answer</th>\n",
       "      <th>Attack Validity</th>\n",
       "      <th>BAD</th>\n",
       "      <th>...</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Repetition</th>\n",
       "      <th>Rephrase Attack</th>\n",
       "      <th>Request Clarification</th>\n",
       "      <th>Ridicule</th>\n",
       "      <th>Sarcasm</th>\n",
       "      <th>Softening</th>\n",
       "      <th>Sources</th>\n",
       "      <th>Viable Transformation</th>\n",
       "      <th>W Qualifiers</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4r2a4d</td>\n",
       "      <td>1467557821</td>\n",
       "      <td>comment: Are you talking about relationships s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4r2a4d</td>\n",
       "      <td>1467558355</td>\n",
       "      <td>comment: I was focusing more on the first (rel...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4r2a4d</td>\n",
       "      <td>1467584235</td>\n",
       "      <td>comment: I've been in a LDR for the past 2 1/2...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4r2a4d</td>\n",
       "      <td>1467559384</td>\n",
       "      <td>comment: It depends on what people want. If yo...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4r2a4d</td>\n",
       "      <td>1467561555</td>\n",
       "      <td>comment: Agreed. But isn't companionship diffe...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10453</th>\n",
       "      <td>7yf2le</td>\n",
       "      <td>1519073471</td>\n",
       "      <td>comment: &lt;quote&gt;Also, there is no secret sauce...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10454</th>\n",
       "      <td>7yf2le</td>\n",
       "      <td>1519073875</td>\n",
       "      <td>comment: you should teach! post: Poverty Sensi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10455</th>\n",
       "      <td>7yf2le</td>\n",
       "      <td>1519074041</td>\n",
       "      <td>comment: Nope there is even less money in that...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10456</th>\n",
       "      <td>7yf2le</td>\n",
       "      <td>1519067247</td>\n",
       "      <td>comment: Ted Bundy had an IQ of 136. Would mor...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10457</th>\n",
       "      <td>7yf2le</td>\n",
       "      <td>1519067730</td>\n",
       "      <td>comment: There will always be outliers. I don’...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9598 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      tree_id        time                                             inputs  \\\n",
       "0      4r2a4d  1467557821  comment: Are you talking about relationships s...   \n",
       "1      4r2a4d  1467558355  comment: I was focusing more on the first (rel...   \n",
       "2      4r2a4d  1467584235  comment: I've been in a LDR for the past 2 1/2...   \n",
       "3      4r2a4d  1467559384  comment: It depends on what people want. If yo...   \n",
       "4      4r2a4d  1467561555  comment: Agreed. But isn't companionship diffe...   \n",
       "...       ...         ...                                                ...   \n",
       "10453  7yf2le  1519073471  comment: <quote>Also, there is no secret sauce...   \n",
       "10454  7yf2le  1519073875  comment: you should teach! post: Poverty Sensi...   \n",
       "10455  7yf2le  1519074041  comment: Nope there is even less money in that...   \n",
       "10456  7yf2le  1519067247  comment: Ted Bundy had an IQ of 136. Would mor...   \n",
       "10457  7yf2le  1519067730  comment: There will always be outliers. I don’...   \n",
       "\n",
       "       Aggressive  Agree But  Agree To Disagree  Alternative  Answer  \\\n",
       "0               0          0                  0            0       0   \n",
       "1               0          0                  0            0       0   \n",
       "2               0          0                  0            0       0   \n",
       "3               0          0                  0            0       0   \n",
       "4               0          1                  0            0       0   \n",
       "...           ...        ...                ...          ...     ...   \n",
       "10453           0          0                  0            0       0   \n",
       "10454           0          0                  0            0       0   \n",
       "10455           0          0                  0            0       0   \n",
       "10456           0          0                  0            0       0   \n",
       "10457           0          0                  0            0       0   \n",
       "\n",
       "       Attack Validity  BAD  ...  Positive  Repetition  Rephrase Attack  \\\n",
       "0                    0    0  ...         0           0                0   \n",
       "1                    0    0  ...         0           0                0   \n",
       "2                    0    0  ...         0           0                0   \n",
       "3                    0    0  ...         0           0                0   \n",
       "4                    0    0  ...         0           0                0   \n",
       "...                ...  ...  ...       ...         ...              ...   \n",
       "10453                0    0  ...         0           0                0   \n",
       "10454                0    0  ...         0           0                0   \n",
       "10455                0    0  ...         1           0                0   \n",
       "10456                0    0  ...         0           0                0   \n",
       "10457                0    0  ...         0           0                0   \n",
       "\n",
       "       Request Clarification  Ridicule  Sarcasm  Softening  Sources  \\\n",
       "0                          1         0        0          0        0   \n",
       "1                          0         0        0          0        0   \n",
       "2                          0         0        0          0        1   \n",
       "3                          0         0        0          0        0   \n",
       "4                          0         0        0          0        0   \n",
       "...                      ...       ...      ...        ...      ...   \n",
       "10453                      0         0        0          0        0   \n",
       "10454                      0         0        1          0        0   \n",
       "10455                      0         0        0          0        0   \n",
       "10456                      0         1        0          0        0   \n",
       "10457                      0         0        0          0        0   \n",
       "\n",
       "       Viable Transformation  W Qualifiers  \n",
       "0                          0             0  \n",
       "1                          0             0  \n",
       "2                          0             0  \n",
       "3                          0             0  \n",
       "4                          0             0  \n",
       "...                      ...           ...  \n",
       "10453                      0             0  \n",
       "10454                      0             0  \n",
       "10455                      0             0  \n",
       "10456                      0             0  \n",
       "10457                      0             0  \n",
       "\n",
       "[9598 rows x 34 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pairs_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bee5717e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_model(model, labels=None):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "\n",
    "    if model.startswith('t5'):\n",
    "        model = AutoModelForSeq2SeqLM.from_pretrained(model)\n",
    "\n",
    "    else:\n",
    "        num_labels = len(labels)\n",
    "        id2label = {i: c for i, c in enumerate(labels)}\n",
    "        label2id = {c: i for i, c in id2label.items()}\n",
    "        problem_type = 'multi_label_classification'\n",
    "        model = AutoModelForSequenceClassification.from_pretrained(model,\n",
    "                                                                   problem_type=problem_type,\n",
    "                                                                   num_labels=num_labels,\n",
    "                                                                   id2label=id2label,\n",
    "                                                                   label2id=label2id)\n",
    "\n",
    "    return model, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "042c41fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model, tokenizer = prepare_model('bert-base-uncased', pairs_df.columns[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e136863",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_classification_input(examples, tokenizer, labels, source_max_length: int=512):\n",
    "    model_inputs = tokenizer(examples[\"inputs\"], max_length=source_max_length,\n",
    "                                padding='max_length', truncation=True, return_tensors='pt')\n",
    "\n",
    "    labels_batch = {k: examples[k] for k in examples.keys() if k in labels}\n",
    "    # create numpy array of shape (batch_size, num_labels)\n",
    "    labels_matrix = np.zeros((len(examples[\"inputs\"]), len(labels)))\n",
    "    # fill numpy array\n",
    "    for idx, label in enumerate(labels):\n",
    "        labels_matrix[:, idx] = labels_batch[label]\n",
    "\n",
    "    model_inputs[\"labels\"] = labels_matrix.tolist()\n",
    "\n",
    "    return model_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "30abb6dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(df, tokenizer, labels):\n",
    "\n",
    "    lpgo = LeavePGroupsOut(5)\n",
    "    for (train_index, test_index) in lpgo.split(df, groups=df['tree_id']):\n",
    "        break\n",
    "\n",
    "    train_df = df.iloc[train_index]\n",
    "    test_df = df.iloc[test_index]\n",
    "\n",
    "\n",
    "\n",
    "    train_dataset = Dataset.from_pandas(train_df)\n",
    "    test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "    train_dataset = train_dataset.map(tokenize_classification_input,\n",
    "                                        batched=True,\n",
    "                                        fn_kwargs={'tokenizer': tokenizer,\n",
    "                                                    'labels': labels,\n",
    "                                                    'source_max_length': 512,\n",
    "                                                    },\n",
    "                                        remove_columns=train_dataset.column_names)\n",
    "    \n",
    "    test_dataset = test_dataset.map(tokenize_classification_input,\n",
    "                                        batched=True,\n",
    "                                        fn_kwargs={'tokenizer': tokenizer,\n",
    "                                                    'labels': labels,\n",
    "                                                    'source_max_length': 512,\n",
    "                                                    },\n",
    "                                        remove_columns=test_dataset.column_names)\n",
    "\n",
    "    return train_dataset, test_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e526ea11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a475528ecac0482985f8073f08042ace",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "380d5e84c588463ea35a5d17041e43a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dataset, test_dataset = prepare_training_data(pairs_df, tokenizer, pairs_df.columns[3:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "68a64da2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# source: https://jesusleal.io/2021/04/21/Longformer-multilabel-classification/\n",
    "def compute_metrics(eval_preds):\n",
    "    predictions, labels = eval_preds\n",
    "    if isinstance(predictions, tuple):\n",
    "        predictions = predictions[0]\n",
    "    # first, apply sigmoid on predictions which are of shape (batch_size, num_labels)\n",
    "    probs = F.sigmoid(torch.Tensor(predictions))\n",
    "    # next, use threshold to turn them into integer predictions\n",
    "    y_pred = np.zeros(probs.shape)\n",
    "    y_pred[np.where(probs >= 0.5)] = 1\n",
    "    # finally, compute metrics\n",
    "    y_true = labels\n",
    "    f1_micro_average = f1_score(y_true=y_true, y_pred=y_pred, average='micro')\n",
    "    roc_auc = roc_auc_score(y_true, probs, average = 'micro')\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    # return as dictionary\n",
    "    metrics = {'f1': f1_micro_average,\n",
    "               'roc_auc': roc_auc,\n",
    "               'accuracy': accuracy}\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "87831c05",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using the `WANDB_DISABLED` environment variable is deprecated and will be removed in v5. Use the --report_to flag to control the integrations used for logging result (for instance --report_to none).\n",
      "/home/eyal/.local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 9224\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 16\n",
      "  Total optimization steps = 1728\n",
      "  Number of trainable parameters = 109506079\n",
      "You're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='472' max='1728' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 472/1728 38:12 < 1:42:06, 0.21 it/s, Epoch 0.82/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Roc Auc</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.455800</td>\n",
       "      <td>0.309332</td>\n",
       "      <td>0.425806</td>\n",
       "      <td>0.716570</td>\n",
       "      <td>0.179144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.259300</td>\n",
       "      <td>0.224503</td>\n",
       "      <td>0.425806</td>\n",
       "      <td>0.752924</td>\n",
       "      <td>0.179144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.203900</td>\n",
       "      <td>0.199843</td>\n",
       "      <td>0.425806</td>\n",
       "      <td>0.765770</td>\n",
       "      <td>0.179144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.190800</td>\n",
       "      <td>0.190972</td>\n",
       "      <td>0.425806</td>\n",
       "      <td>0.772800</td>\n",
       "      <td>0.179144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.177500</td>\n",
       "      <td>0.189318</td>\n",
       "      <td>0.425806</td>\n",
       "      <td>0.765074</td>\n",
       "      <td>0.179144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.175700</td>\n",
       "      <td>0.185095</td>\n",
       "      <td>0.425806</td>\n",
       "      <td>0.774238</td>\n",
       "      <td>0.179144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.175100</td>\n",
       "      <td>0.182381</td>\n",
       "      <td>0.425806</td>\n",
       "      <td>0.784332</td>\n",
       "      <td>0.179144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.169600</td>\n",
       "      <td>0.181504</td>\n",
       "      <td>0.425806</td>\n",
       "      <td>0.780319</td>\n",
       "      <td>0.179144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.170400</td>\n",
       "      <td>0.180343</td>\n",
       "      <td>0.425806</td>\n",
       "      <td>0.789238</td>\n",
       "      <td>0.179144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 374\n",
      "  Batch size = 1\n",
      "/home/eyal/.local/lib/python3.10/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "Saving model checkpoint to /tmp/results/checkpoint-50\n",
      "Configuration saved in /tmp/results/checkpoint-50/config.json\n",
      "Model weights saved in /tmp/results/checkpoint-50/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/results/checkpoint-50/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/results/checkpoint-50/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 374\n",
      "  Batch size = 1\n",
      "/home/eyal/.local/lib/python3.10/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "Saving model checkpoint to /tmp/results/checkpoint-100\n",
      "Configuration saved in /tmp/results/checkpoint-100/config.json\n",
      "Model weights saved in /tmp/results/checkpoint-100/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/results/checkpoint-100/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/results/checkpoint-100/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 374\n",
      "  Batch size = 1\n",
      "/home/eyal/.local/lib/python3.10/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "Saving model checkpoint to /tmp/results/checkpoint-150\n",
      "Configuration saved in /tmp/results/checkpoint-150/config.json\n",
      "Model weights saved in /tmp/results/checkpoint-150/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/results/checkpoint-150/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/results/checkpoint-150/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 374\n",
      "  Batch size = 1\n",
      "/home/eyal/.local/lib/python3.10/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "Saving model checkpoint to /tmp/results/checkpoint-200\n",
      "Configuration saved in /tmp/results/checkpoint-200/config.json\n",
      "Model weights saved in /tmp/results/checkpoint-200/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/results/checkpoint-200/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/results/checkpoint-200/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 374\n",
      "  Batch size = 1\n",
      "/home/eyal/.local/lib/python3.10/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "Saving model checkpoint to /tmp/results/checkpoint-250\n",
      "Configuration saved in /tmp/results/checkpoint-250/config.json\n",
      "Model weights saved in /tmp/results/checkpoint-250/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/results/checkpoint-250/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/results/checkpoint-250/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 374\n",
      "  Batch size = 1\n",
      "/home/eyal/.local/lib/python3.10/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "Saving model checkpoint to /tmp/results/checkpoint-300\n",
      "Configuration saved in /tmp/results/checkpoint-300/config.json\n",
      "Model weights saved in /tmp/results/checkpoint-300/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/results/checkpoint-300/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/results/checkpoint-300/special_tokens_map.json\n",
      "Deleting older checkpoint [/tmp/results/checkpoint-50] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 374\n",
      "  Batch size = 1\n",
      "/home/eyal/.local/lib/python3.10/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "Saving model checkpoint to /tmp/results/checkpoint-350\n",
      "Configuration saved in /tmp/results/checkpoint-350/config.json\n",
      "Model weights saved in /tmp/results/checkpoint-350/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/results/checkpoint-350/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/results/checkpoint-350/special_tokens_map.json\n",
      "Deleting older checkpoint [/tmp/results/checkpoint-100] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 374\n",
      "  Batch size = 1\n",
      "/home/eyal/.local/lib/python3.10/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "Saving model checkpoint to /tmp/results/checkpoint-400\n",
      "Configuration saved in /tmp/results/checkpoint-400/config.json\n",
      "Model weights saved in /tmp/results/checkpoint-400/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/results/checkpoint-400/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/results/checkpoint-400/special_tokens_map.json\n",
      "Deleting older checkpoint [/tmp/results/checkpoint-150] due to args.save_total_limit\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 374\n",
      "  Batch size = 1\n",
      "/home/eyal/.local/lib/python3.10/site-packages/torch/nn/functional.py:1967: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
      "Saving model checkpoint to /tmp/results/checkpoint-450\n",
      "Configuration saved in /tmp/results/checkpoint-450/config.json\n",
      "Model weights saved in /tmp/results/checkpoint-450/pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/results/checkpoint-450/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/results/checkpoint-450/special_tokens_map.json\n",
      "Deleting older checkpoint [/tmp/results/checkpoint-200] due to args.save_total_limit\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [12]\u001b[0m, in \u001b[0;36m<cell line: 26>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m training_args \u001b[38;5;241m=\u001b[39m TrainingArguments(\n\u001b[1;32m      2\u001b[0m     output_dir\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/tmp/results/\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      3\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-5\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     14\u001b[0m     save_total_limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     15\u001b[0m )\n\u001b[1;32m     17\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(\n\u001b[1;32m     18\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m     19\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mtokenizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     23\u001b[0m     compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m     24\u001b[0m )\n\u001b[0;32m---> 26\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:1527\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_wrapped \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\n\u001b[1;32m   1524\u001b[0m inner_training_loop \u001b[38;5;241m=\u001b[39m find_executable_batch_size(\n\u001b[1;32m   1525\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inner_training_loop, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_batch_size, args\u001b[38;5;241m.\u001b[39mauto_find_batch_size\n\u001b[1;32m   1526\u001b[0m )\n\u001b[0;32m-> 1527\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1528\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/trainer.py:1780\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1774\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1775\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1778\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1779\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m-> 1780\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1781\u001b[0m ):\n\u001b[1;32m   1782\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1783\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   1784\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir='/tmp/results/',\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=1,\n",
    "    per_device_eval_batch_size=1,\n",
    "    gradient_accumulation_steps=16,\n",
    "    eval_accumulation_steps=4,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=IntervalStrategy.STEPS,\n",
    "    save_strategy=IntervalStrategy.STEPS,\n",
    "    logging_steps=50,\n",
    "    save_steps=50,\n",
    "    save_total_limit=5\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f876e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
